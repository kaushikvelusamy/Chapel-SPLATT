Look for places with direct array assignment and see if we can replace with ref,
as a direct assignment makes a copy of the array

Change all loops to use domains, if possible. This is supposed to speed-up the runtime bounds checking

Change memcpy calls, if possible, to use direct array assignment.

Look for places to use slicing instead of loops when doing assignment

Replace direct C-interfacing with more Chapel-like statements

Do entire-array operations work in parallel automatically? As in, does sqrt(A) perform the sqrt() function
on each element of A in parallel?

It'd be nice to have some more fine-grain control over BLAS/LAPACK functions.

Is there a Chapel equivalent to a omp for within an omp parallel section? What happens with
a forall within a coforall?

Having a built in lock would be great, but not entirely necessary; using sync vars isn't too bad.

Do the linear algebra routines on matrices/vectors execute in parallel?

Be careful when directly porting OMP code that is of the form:

omp parallel
{
    stuff
    omp for
    for i...
        stuff
    more stuff
}

There is an implicit barrier after the omp for. We need to do the barrier explicitly in
Chapel

Not being able to store ref in classes is a draw back

It seems difficult to create a reference to an array of records/objects. This is easy in
C because we just say something like:
    myType *ref = myRecords;    //myRecords is an array of myType objects
Then whatever we do to myRecord affects ref and vice versa. But in Chapel, the above statement
would be an array assignment, which creates a copy of myRecords. 


Given two matrices, it is difficult to re-assign the row of one to be a row of the other. In
C, if I have the two matrices stored as an array of pointers, then its as simple as

mat1[i] = mat2[i]

But in Chapel, if you try to do this with array slicing:

mat1[i, ..] = mat2[i, ..]

The performance is terrible because array slicing is so slow. So you need to
get C pointers to the matrices and then use pointer arithmetic. Another solution
is to have a Chapel array of arrays. This still requires getting pointers as you
don't want to do a copy, but it does make it cleaner.

In general, array creation is expensive. Creating an array of 2 ints is expensive
enough when done enough times (i.e. quicksort) to make a considerable difference
(2.5x).

You cannot store an array of arrays where the sub-arrays have different sizes. This
is taken from a Stackoverflow post dated July 14 2017:
W.r.t. "jagged arrays": While Chapel was designed such that arrays-of-arrays could be used for "jagged"/"skyline" arrays (ones in which the subarrays have different sizes), the current implementation only supports cases in which the inner arrays all share the same domain (index set). This means that in practice such arrays will still be (virtually) rectangular at present. The typical workaround for representing a truly jagged array is to store an array of objects where each stores its own domain/array fields---this permits the different sub-arrays to have different sizes

This is exactly what we do, so we're good.


dgemm is actually working fine in Chapel. It's just that our matrices are very rectangular, which I think is not
how BLAS is generally optimized. I suspect that each dimension needs to be a certain size before it can be fully
advantageous.
